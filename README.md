# [CS 330 - Deep Multi-Task and Meta Learning](https://cs330.stanford.edu/) 
## Pre-training a Hierarchical RL Controller using Hindsight Experience Replay
Collaborators:
- Georgia Gabriela Sampaio (georgia@cs.stanford.edu; [Computer Science](https://cs.stanford.edu/), [Electrical Engineering](https://ee.stanford.edu/))
- Max Sobol Mark (maxsobolmark@stanford.edu; [Computer Science](https://cs.stanford.edu/))

#description
TBD

#references:
TBD

# TODO list:
- Decide which agent from ACME we're going to use, and set it up with entropy maximization.
- Replicate the latent variable-conditioned policy model.
- Replicate the discriminator.
- Replicate Hierarchical RL environments, adding goals.
- Create hierarchical policy.